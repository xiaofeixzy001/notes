[TOC]

# 流程系统

目前已经完成了流程定义的实现，下面要使用它来实现具体的任务流程的流转。

## 问题

目前表设计存在如下问题：

1，用户需要频繁查询正在运行任务的状态，使用pipeline表，以减少对track表的查询，提高效率。

2，pipeline表不能很好的描述多节点，如果描述当前运行的流程有分支，且正在执行的超过一个顶点，就不好描述了，因为每一个顶点都有自己的状态，这张表就要描述一对多关系，目前不合适。

3，pipeline不适合描述有多起点的流程。

4，如果一个流程任务对应的顶点大于1，pipeline表不适合，要求前面的所有任务都必须是成功状态。

## 解决办法

- 抛弃原有pipeline表设计，修改为用来记录任务流信息的表，字段有g_id, name, desc, state等。
  -  g_id表示使用哪一个DAG；
  - name是任务流名称，例如WEB服务器检查；
  - desc是任务流的详细描述；
  - state用于记录整个任务流的状态，有3种：
    - 有节点运行就是STATE_RUNNING
    - 有节点失败就是STATE_FAILED
    - 全部节点都成功就是STATE_FINISH。

- 用track表来记录流程信息，一个任务流产生，就在track表里记录数据，使用pipeline的任务流id即p_id，并记录状态。

- 任务节点执行状态，有5种：
  - STATE_WAITING = 0
  - STATE_PENDING = 1
  - STATE_RUNNING = 2
  - STATE_SUCCEED = 3
  - STATE_FAILED = 4

- 如何解决频繁查询全部节点信息的状态？
  - 创建任务时，从vertex表中复制所有相关graph的顶点信息到track表，所有顶点状态为STATE_WAITING，起点要被设置为STATE_PENDING。

- 如何解决反复查询当前正在执行的任务？
  - 在state字段上建立索引，提高查询效率。

- 什么是正在执行的任务节点？
  - STATE_WAITING表示等待执行，STATE_PENDING表示入调度器准备执行，STATE_RUNNING表示此节点正在执行。

- 如何描述一个任务流执行完成？
  - 有一个任务顶点执行失败，则表示整个任务执行失败，所有节点不再执行，pipeline表中state状态为STATE_FAILED；所有节点都成功STATE_SUCCEED，则将pipeline中的状态置为STATE_FINISH。

- 如果一个流程有多个起点，在所有节点信息复制到track表中的时候，就将这些节点的状态置为STATE_PENDING。

- 如果一个流程节点的入度大于1，需要它的前驱节点都要是成功状态STATE_SUCCEED，才能被置为STATE_PENDING。

- 如果流程节点执行完成，就是成功、失败这两种状态之一，这些状态都要写入track表，如果track表中该p_id的所有节点都成功，pipeline中该任务完成，状态置为STATE_FINISH。

- 如果一个流程节点有多终点，同上，所有节点都必须成功，否则就是失败。

- 如果一个DAG定义中有孤立的点，如A -> B, C，C是一个孤立的顶点，如何解决？
  - 可以认为不合法，使用所有顶点集 - 所有边关联的顶点集 = 孤立的顶点集可以检测出孤立节点。
  - 可以认为合法，就是入度为0的顶点，可以执行。可以认为是多起点，同时又是多终点。
  - 本项目认为合法。

- 节点流转，要求所有前驱节点必须是成功状态STATE_SUCCEED。

- track表增加记录用户操作的脚本script字段，减少使用input替换的时间。

综上，表模型修改如下：

![image-20200405164621397](%E6%B5%81%E7%A8%8B%E7%B3%BB%E7%BB%9F.assets/image-20200405164621397.png)

取消pipeline与vertex的多对一关系，修改current字段为name，varchar类型。

修改model.py

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# __Author__: XiaoFei

from sqlalchemy import Column, Integer, String, Text, ForeignKey, create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship, sessionmaker
from .config import URL, DATABASE_DEBUG
from functools import wraps

# 如果组合可以表示状态的话,就要设计为1,2,4,8,16,32等来表示
STATE_WAITING =0
STATE_PENDING = 1
STATE_RUNNING = 2
STATE_SUCCEED = 3
STATE_FAILED = 4
STATE_FINISH = 5

Base = declarative_base()


class Graph(Base):

    __tablename__ = 'graph'

    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(String(48), nullable=False, unique=True)
    desc = Column(String(100), nullable=True)
    checked = Column(Integer, nullable=False, default=0)
    sealed = Column(Integer, nullable=False, default=0)

    #  从图表查看所有顶点和边的信息
    vertexes = relationship('Vertex', foreign_keys='Vertex.g_id')
    edges = relationship('Edge', foreign_keys='Edge.g_id')

    def __repr__(self):
        return '<Graph {} {}>'.format(self.id, self.name)

    __str__ = __repr__


class Vertex(Base):

    __tablename__ = 'vertex'

    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(String(48), nullable=False)
    script = Column(Text, nullable=True)
    input = Column(Text, nullable=True)
    g_id = Column(Integer, ForeignKey('graph.id'), nullable=False)

    # 从顶点表去查它的边
    graph = relationship('Graph')
    tails = relationship('Edge', foreign_keys='[Edge.tail]')
    heads = relationship('Edge', foreign_keys='Edge.head')

    def __repr__(self):
        return '<Vertex {} {}>'.format(self.id, self.name)

    __str__ = __repr__


class Edge(Base):

    __tablename__ = 'edge'

    id = Column(Integer, primary_key=True, autoincrement=True)
    tail = Column(Integer, ForeignKey('vertex.id'), nullable=False)
    head = Column(Integer, ForeignKey('vertex.id'), nullable=False)
    g_id = Column(Integer, ForeignKey('graph.id'), nullable=False)

    def __repr__(self):
        return '< Edge {} <{} {}> >'.format(self.id, self.tail, self.head)

    __str__ = __repr__


class Pipeline(Base):

    __tablename__ = 'pipeline'

    id = Column(Integer, primary_key=True, autoincrement=True)
    g_id = Column(Integer, ForeignKey('graph.id'), nullable=False)
    # current = Column(Integer, ForeignKey('vertex.id'), nullable=False)
    name = Column(String(48), nullable=True)
    state = Column(Integer, nullable=False, default=STATE_WAITING)
    desc = Column(String(100))

    # 从pipeline去查所有节点信息
    # pipeline = db.session.query(Pipeline).filter(id=1).one()
    # pipeline.tracks  [Track类型的对象]
    tracks = relationship('Track', foreign_keys='Track.p_id')

    def __repr__(self):
        return '<Pipeline {} >'.format(self.id)

    __str__ = __repr__


class Track(Base):

    __tablename__ = 'track'

    id = Column(Integer, primary_key=True, autoincrement=True)
    p_id = Column(Integer, ForeignKey('pipeline.id'), nullable=False)
    v_id = Column(Integer, ForeignKey('vertex.id'), nullable=False)
    input = Column(Text, nullable=True)
    script = Column(Text, nullable=True)
    output = Column(Text, nullable=True)
    state = Column(Integer, index=True, nullable=False, default=STATE_WAITING)

    # 通过Track表查指定某一个pipeline内的所有顶点信息,如名字
    # tracks = db.session.query(Track).filter(p_id = 1).all()  list
    # t.vertex.name for t in tracks
    vertex = relationship('Vertex')  # t = Track(), t.vertex.name
    pipeline = relationship('Pipeline')  # t.pipeline.name

    def __repr__(self):
        return '<Track {} {} {} {} >'.format(self.__class__.__name__, self.id, self.p_id, self.v_id)

    __str__ = __repr__


def singleton(cls):
    instance = None
    @wraps(cls)
    def wrapper(*args, **kwargs):
        nonlocal instance
        if not instance:
            instance = cls(*args, **kwargs)
        return instance
    return wrapper


@singleton
class Database:
    def __init__(self, url, **kwargs):
        self._engine = create_engine(url, **kwargs)
        self._session = sessionmaker(bind=self._engine)()

    @property
    def session(self):
        return self._session

    @property
    def engine(self):
        return self._engine

    def create_all(self):
        Base.metadata.create_all(self._engine)

    def drop_all(self):
        Base.metadata.drop_all(self._engine)

    def __repr__(self):
        return "<{} {} {}>".format(self.__class__.__name__, id(self), self.__dict__)


db = Database(URL, echo=DATABASE_DEBUG)

```

relationship不影响建表,只对查询有作用。

# pipeline启动

开启一个流程前，需要选择一个checked为1的即验证通过的DAG，然后为流程起名，填写描述，提交数据库。

创建一个流程后，得到的流程id即p_id，将所选择的DAG的所有顶点都查取回来写入到Track表中。

读取所有边，找出入度为0的顶点，这些顶点在Track表中的状态值设置为RUNNING，其他非起始节点设置为WAITING。

找出入度为0的顶点：

SQL语句如下：

```mysql
SELECT * FROM vertex WHERE vertex.g_id = 1 AND vertex.id NOT IN (
   SELECT edge.head FROM edge WHERE edge.g_id = 1
)
```

sqlalchemy代码如下：

```python
starts = query.filter(Vertex.id.notin_(
        db.session.query(Edge.head).filter(Edge.g_id == 1)
    )).all()
```



在pipeline包下，新建executor.py

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# __Author__: xiaofei
from .model import db, Graph, Vertex, Edge, Pipeline, Track
from .model import STATE_WAITING, STATE_FAILED, STATE_FINISH, STATE_PENDING, STATE_RUNNING, STATE_SUCCEED
from .service import transactional


@transactional
def start(g_id, name: str, desc=''):
    # checked
    g = db.session.query(Graph).filter((Graph.id == g_id) & (Graph.checked == 1)).first()
    if not g:
        return

    # 找到所有顶点,拷贝到track
    vertex_query = db.session.query(Vertex).filter(Vertex.g_id == g_id)
    vertexes = vertex_query.all()
    if not vertexes:
        return

    # 新建任务流
    p = Pipeline()
    p.g_id = g_id
    p.name = name
    p.desc = desc
    p.state = STATE_RUNNING
    db.session.add(p)

    # 将作为起点的顶点的状态改为PENDING,入度为0的顶点zds
    zds_query = vertex_query.filter(Vertex.id.notin_(
        db.session.query(Edge.head).filter(Edge.g_id == g_id)
    )).all()  # list
    zds = [v.id for v in zds_query]
    print(zds, '~~~~~~~~')

    # Track表初始化所有节点,写入track表
    for v in vertexes:
        t = Track()
        t.v_id = v.id
        t.pipeline = p
        t.state = STATE_PENDING if v.id in zds else STATE_WAITING
        db.session.add(t)

    # 封闭graph的sealed
    if g.sealed == 0:
        g.sealed = 1
        db.session.add(g)

    return p
```

在app.py中添加创建流程代码，并测试执行。

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
# __Author__: xiaofei
import json
from pipeline.model import Graph, Vertex, Edge, Pipeline, Track, db
from pipeline.service import create_graph, add_edge, add_vertex, del_edge, del_vertex
from pipeline.service import check_graph
from pipeline.executor import start


def test_create_dag():
    ...


def test_check_all_graph():
    ...


# db.drop_all()
# db.create_all()
# test_create_dag()
# test_check_all_graph()
start(1, '测试流程1')
```



# 状态查询

获取指定pipeline流程的track信息

方法一：

基于ORM定义的relationship

```python
def show_pipeline1(p_id, state=STATE_PENDING):
    """
    显示指定pipeline的历史信息
    流程信息(包含流程名字,流程id,流程状态)
    顶点信息(包含顶点状态,顶点里面的input和script)
    :param id: p_id
    :param state:
    :return: list
    """
    ret = []
    pipeline_track = db.session.query(Track).filter(Track.p_id == p_id).filter(Track.state == state)
    for track in pipeline_track:
        ret.append((
            track.pipeline.id,
            track.pipeline.name,
            track.pipeline.state,
            track.id,
            track.v_id,
            track.vertex.input,
            track.vertex.script
        ))
    return ret
```

方法二：

基于inner join子句

- INNER JOIN子句将一个表中的行与其他表中的行进行匹配，并允许从两个表中查询包含列的行记录。INNER JOIN子句是SELECT语句的可选部分，它出现在FROM子句之后。在使用INNER JOIN子句之前，必须指定以下条件：
  - 首先，在FROM子句中指定主表。
  - 其次，表中要连接的主表应该出现在INNER JOIN子句中。理论上说，可以连接多个其他表。 但是，为了获得更好的性能，应该限制要连接的表的数量(最好不要超过三个表)。
  - 第三，连接条件或连接谓词。连接条件出现在INNER JOIN子句的ON关键字之后。连接条件是将主表中的行与其他表中的行进行匹配的规则。

比如这里以Track表为主，内联Pipeline表和Vertex表

![image-20200406175431278](%E6%B5%81%E7%A8%8B%E7%B3%BB%E7%BB%9F.assets/image-20200406175431278.png)

![image-20200406175520643](%E6%B5%81%E7%A8%8B%E7%B3%BB%E7%BB%9F.assets/image-20200406175520643.png)

![image-20200406175601509](%E6%B5%81%E7%A8%8B%E7%B3%BB%E7%BB%9F.assets/image-20200406175601509.png)



SQL语句

```mysql
SELECT
	pipeline.id,
	pipeline.`name`,
	pipeline.state,
	track.id,
	track.v_id,
	track.state,
	vertex.input,
	vertex.script
FROM
	track
INNER JOIN pipeline ON track.p_id = pipeline.id
INNER JOIN vertex ON track.v_id = vertex.id
WHERE track.p_id and track.state = 1
```

python代码

```python
# 方法二: 基于join连表查询
def show_pipeline(p_id, states=[STATE_PENDING], exclude=[STATE_FAILED]):
    """
    显示指定pipeline的历史信息
    流程信息(包含流程名字,流程id,流程状态)
    顶点信息(包含顶点状态,顶点里面的input和script)
    :param id: p_id
    :param state:
    :return: list
    """
    # 定义一张主表,通过主表查其他表
    query = db.session.query(
        Pipeline.id, Pipeline.name, Pipeline.state,
        Track.id, Track.v_id, Track.state,
        Vertex.input, Vertex.script
    ).join(Track, Pipeline.id == Track.p_id)\
        .join(Vertex, Vertex.id == Track.v_id)\
        .filter(Pipeline.state.notin_(exclude))\
        .filter(Track.p_id == p_id)\
        .filter(Track.state.in_(states)).all()
    return query
```

app.py查询测试

```python
from pipeline.executor import show_pipeline

ps = show_pipeline(1, state=STATE_PENDING)
p_id, p_name, p_state, t_id, v_id, t_state, input, script = ps[0]
print(
    "pipeline_id: {},\
    pipeline_name: {},\
    pipeline_state: {},\
    track_id: {}, \
    track_state: {}, \
    vertex_id: {}, \
    vertex_input: {}, \
    vertex_script: {}".format(p_id, p_name, p_state, t_id, t_state, v_id, input, script)
)
```



# input验证和脚本执行

## 功能需求

开启一个流程后，定点可能设置了input，这时就要提供一个界面，让用户填写参数。这是一个交互过程，也可以实现为自动填写参数。

获取参数后需要验证，验证失败抛出异常，验证成功就用来替换执行脚本，生成可以运行的脚本。

然后将参数、脚本存入数据库的track表。

在track表添加script字段，存储执行的脚本。

```python
input = {
            'ip': {
                'type': 'str',
                'required': True,
                'default': '127.0.0.1'
            }
        }

script = {
    'script': 'echo "test1.A"\nping {ip}',
    'next': 'B'
}
```

input中，required表示是否必须输入ip，为False则自动使用默认值default为ip的值。

script中，{ip}占位符，用户提供ip参数后，使用ip名称进行替换。

ping命令在windows下，默认4次自动结束，但如果在linux下，ping会一直执行下去，需要加参数执行：

```shell
# ping百度,在8秒内发送2次,成功返回0,未成功返回非0
ping www.baidu.com -w 8 -c 2; echo $?
```



## 模拟浏览器交互

假设在浏览器中，用户看到了当前显示的信息，需要提供参数，显示交互界面，让用户输入，然后提交数据，进行验证，替换script脚本中的占位符，生成可以执行的脚本。

service.py

```python
from .model import Graph, Vertex, Edge, Pipeline, Track, db
from functools import wraps
from collections import defaultdict
import simplejson
import re

# 类型转换用
TYPES = {
    'str': str,
    'string': str,
    'int': int,
    'integer': int,
    #'ip': 'IPTYPE'  # 扩展,ip类型检测
}

def transactional(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        ret = func(*args, **kwargs)
        try:
            db.session.commit()
            return ret
        except Exception as e:
            print(e)
            db.session.rollback()
    return wrapper

# {"ip": {"type": "str", "required": true, "default": "192.168.100.10"}}
# {"script": "echo \"test1.A\"\nping {ip}", "next": "B"}
def finish_params(v_id, d: dict):
    """
    参数类型验证,根据顶点规定的规则验证浏览器提交的数据是否合规
    :param v_id: 顶点id
    :param d: 字典,浏览器提交的ip数据
    :return: tuple
    """
    params = {}
    inp = db.session.query(Vertex.input, Vertex.script).filter(Vertex.id == v_id).first()
    """
    inp = (
        '{"ip": {"type": "str", "required": true, "default": "192.168.100.10"}}',
        '{"script": "echo \\"test1.A\\"\\nping {ip}", "next": "B"}'
    )
    """
    script = ''
    if inp:
        script = inp[1]
        inp = simplejson.loads(inp[0])
        for k, v in inp.items():
            if k in d.keys():
                params[k] = TYPES[inp[k].get('type', 'str')](d[k])
            elif inp[k].get('default') is not None:
                params[k] = TYPES[inp[k].get('type', 'str')](inp[k].get('default'))
            else:
                raise TypeError()
    return params, script


@transactional
def finish_script(t_id, params: dict, script: str):
    """
    占位符替换,脚本转换
    :param params: ret, dict
    :param script: dict
    :return:
    """
    newline = ''
    print(params, type(params))
    print(script, type(script))  # str

    if script:
        script = simplejson.loads(script).get('script', '')
        # script = "echo \\"test1.A\\"\\nping {ip}"
        # 替换{ip}为地址
        regex = re.compile(r'{([^{}]+)}')
        start = 0
        for matcher in regex.finditer(script):
            newline += script[start: matcher.start()]
            print(matcher, matcher.group(1))
            key = matcher.group(1)
            tmp = params.get(key, '')
            newline += str(tmp)
            start = matcher.end()
        else:
            newline += script[start:]

        # 入库,Track表
        t = db.session.query(Track).filter(Track.id == t_id).first()
        if t:
            t.input = simplejson.dumps(params)
            t.script = newline
            db.session.add(t)

    return newline
```



app.py

```python
from pipeline.executor import show_pipeline
from pipeline.service import finish_params, finish_script

ps = show_pipeline(1)
p_id, p_name, p_state, t_id, v_id, t_state, inp, script = ps[0]

d = {}
if inp:
    try:
        inp = simplejson.loads(inp)
        if not isinstance(inp, dict):
            inp = {}
    except:
        inp = {}

    for k, v in inp.items():
        if v.get('required', False):
            i = input('{} = '.format(k)).strip()
            d[k] = i
    print(d)

params, script = finish_params(v_id, d)
script = finish_script(t_id, params, script)
print(script)
```



# 脚本执行

执行脚本，执行的是命令，命令就是写好的程序，程序执行就是一个个进程。

python有很多运行进程的方式，不过都已过时，建议使用subprocess模块，启用子进程。

## subprocess

示例

```python
import subprocess
from tempfile import TemporaryFile

p = subprocess.Popen('echo hello', shell=True, stdout=subprocess.PIPE)
code = p.wait()  # 阻塞等待命令执行完毕
text = p.stdout.read()
print(code, text)

# 输入结果很大,使用临时文件模块
with TemporaryFile('w+') as f:
    p = subprocess.Popen('ping www.baidu.com', shell=True, stdout=f)
    code = p.wait()
    f.seek(0)
    text = f.read()
    print(code, text)
```

由于wait会阻塞，所以使用多线程，使用subprocess的Popen开启子进程执行，但开启线程后返回的结果不能直接拿到。

使用concurrent.futures来异步并发执行，并获取返回的结果。

## concurrent.futures

通过示例回顾一下

```python
import random
import time
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed

futures = {}

def test_func(s, key):
    print('enter~~~{}s, key={}'.format(threading.current_thread(), s, key))
    threading.Event().wait(s)
    if key == 3:
        raise Exception('{} failde'.format(key))
    return 'OK {}'.format(threading.current_thread())

def run(fs):
    while True:
        time.sleep(1)
        print("*" * 20)
        print(fs, '~~~~~~~~')
        # print(as_completed(fs), '*************')
        """
        只要有一个任务没有完成就阻塞,完成一个,执行一个.
        如果内部有异常result()会抛出异常
        有异常也算执行完了complete
        fs为空也不阻塞
        """
        for future in as_completed(fs):
            # print(as_completed(fs), '111111111')
            # print(future, '2222222222')
            id = fs[future]  # 字典的value
            try:
                print(id, future.result(), '~~~~~')
            except Exception as e:
                print(e)
                print(id, 'failed')

threading.Thread(target=run, args=(futures,)).start()

time.sleep(5)

with ThreadPoolExecutor(max_workers=3) as executor:
    for i in range(7):
        futures[executor.submit(test_func, random.randint(1, 8), i)] = i


"""
{}
********************
{}
********************
{}
********************
{}
********************
enter~~~<Thread(ThreadPoolExecutor-0_0, started daemon 10056)>s, key=6
enter~~~<Thread(ThreadPoolExecutor-0_1, started daemon 1776)>s, key=7
{<Future at 0x2b45e8befd0 state=running>: 0, <Future at 0x2b45eb5bda0 state=running>: 1}
********************
enter~~~<Thread(ThreadPoolExecutor-0_2, started daemon 12080)>s, key=8
enter~~~<Thread(ThreadPoolExecutor-0_0, started daemon 10056)>s, key=7
<generator object as_completed at 0x000002B45EB5F468> 1111111
<Future at 0x2b45e8befd0 state=finished returned str> 22222222
0 OK <Thread(ThreadPoolExecutor-0_0, started daemon 10056)> 333333333
enter~~~<Thread(ThreadPoolExecutor-0_1, started daemon 1776)>s, key=2
<generator object as_completed at 0x000002B45EB5F468> 1111111
<Future at 0x2b45eb5bda0 state=finished returned str> 22222222
1 OK <Thread(ThreadPoolExecutor-0_1, started daemon 1776)> 333333333
enter~~~<Thread(ThreadPoolExecutor-0_2, started daemon 12080)>s, key=7
<generator object as_completed at 0x000002B45EB5F468> 1111111
<Future at 0x2b45eb65080 state=finished returned str> 22222222
2 OK <Thread(ThreadPoolExecutor-0_2, started daemon 12080)> 333333333
enter~~~<Thread(ThreadPoolExecutor-0_1, started daemon 1776)>s, key=8
<generator object as_completed at 0x000002B45EB5F468> 1111111
<Future at 0x2b45eb65780 state=finished returned str> 22222222
4 OK <Thread(ThreadPoolExecutor-0_1, started daemon 1776)> 333333333
<generator object as_completed at 0x000002B45EB5F4C0> 1111111
<Future at 0x2b45eb656a0 state=finished raised Exception> 22222222
3 failde
3 failed
...
"""
```

首先启动线程，执行任务run函数，传参空字典futures，睡5秒，在此期间，循环打印run函数执行结果，由于此时futures字典为空，for循环为空，所以会一直打印空字典，直到5秒后。

5秒后，开起线程池，里面起3个线程。每个线程提交一个任务test_func函数，将线程对象作为futures字典的key，i作为value。

然后run函数检测到future字典不再为空，开始遍历字典的key并等待其test_func函数的执行结果。一旦有结果后就继续向后执行，打印，有异常报异常。

只要有一个任务没有完成就阻塞,完成一个,执行一个。
如果内部有异常result()会抛出异常。
有异常也算执行完了complete。
fs为空不阻塞。

# 执行器类实现

调用执行器的execute方法，自动将任务提交，并异步执行。

executor.py

```python
from .model import db, Graph, Vertex, Edge, Pipeline, Track
from .model import STATE_WAITING, STATE_FAILED, STATE_FINISH, STATE_PENDING, STATE_RUNNING, STATE_SUCCEED
from .service import transactional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from subprocess import Popen
from tempfile import TemporaryFile
import threading
import time
import uuid
from queue import Queue


class Executor:
    def __init__(self, works=5):
        self.__tasks = {}
        self.__pool = ThreadPoolExecutor(max_workers=works)
        self.__event = threading.Event()
        self.__queue = Queue()
        threading.Thread(target=self._run).start()
        threading.Thread(target=self._save_track).start()

    def _execute(self, script, key):
        # script多行的
        codes = 0
        output = []
        with TemporaryFile('a+') as f:
            for line in script.splitlines():
                p = Popen(line, shell=True, stdout=f)
                code = p.wait()  # 阻塞等
                codes += code
            f.flush()
            f.seek(0)
            text = f.read()
            output.append(text)
        return codes, '\n'.join(output)

    def execute(self, p_id, t_id, script: str):
        """异步执行方法,提交数据就行了,运行后会提供结果,成功或失败"""
        key = uuid.uuid4().hex  # key未使用,以后不重复key或id可以使用uuid
        try:
            track = db.session.query(Track).filter(Track.id == t_id).one()
            self.__tasks[self.__pool.submit(self._execute, script, key)] = (key, p_id, t_id)
            track.state = STATE_RUNNING
            db.session.add(track)
            db.session.commit()
        except Exception as e:
            db.session.rollback()
            print(e)

    def _run(self):
        """线程等待任务"""
        while not self.__event.wait(1):
            for future in as_completed(self.__tasks):  # 可能阻塞
                key, p_id, t_id = self.__tasks[future]
                try:
                    code, text = future.result()
                    # 拿到结果干什么
                    # del self.__tasks[future]
                    self.__queue.put((p_id, t_id, code, text))
                except Exception as e:
                    print(key, 'Failed')
                    print(e)
                finally:
                    del self.__tasks[future]

    def _save_track(self):
        # 存储结果,从Q里面取数据存储
        while True:
            p_id, t_id, code, text = self.__queue.get()  # 阻塞取
            track = db.session.query(Track).filter(Track.v_id == t_id).first()
            # 修改状态
            track.state = STATE_SUCCEED if code == 0 else STATE_FAILED
            track.output = text

            # 失败,必须立即将任务流pipeline的状态置为失败
            if code != 0:
                track.pipeline.state = STATE_FAILED
            db.session.add(track)
            try:
                db.session.commit()
            except Exception as e:
                print(e)
                db.session.rollback()


# 全局任务执行对象
EXECUTOR = Executor()
```

app.py

```python
ps = show_pipeline(1)
print(ps, '~~~~~~~~')
p_id, p_name, p_state, t_id, v_id, t_state, inp, script = ps[0]

d = {}
if inp:
    try:
        inp = simplejson.loads(inp)
        if not isinstance(inp, dict):
            inp = {}
    except:
        inp = {}

    for k, v in inp.items():
        if v.get('required', False):
            i = input('{} = '.format(k)).strip()
            d[k] = i
    print(d)


params, script = finish_params(v_id, d)
script = finish_script(t_id, params, script)
print(script)

EXECUTOR.execute(p_id, t_id, script)
```















































































