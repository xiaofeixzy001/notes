[TOC]

# **多进程**

由于Python的GIL，多线程未必是CPU密集型程序好的选择。

多进程可以在完全独立的进程环境中运行程序，可以充分利用多处理器。

但是进程本身的隔离带来的数据不共享也是一个问题，并且比线程重量级。

## multiprocessing

multiprocessing模块用来开启子进程，并在子进程中执行我们定制的任务（比如函数），该模块与多线程模块threading的编程接口类似。

multiprocessing模块的功能众多：

支持子进程

通信和共享数据

执行不同形式的同步

提供了Process,Queue,Pipe,Lock等类组件。

[需要再次强调的一点是：与线程不同，进程没有任何共享状态，进程修改的数据，改动仅限于该进程内.]

### Process

multiprocessing.Process(group,target,name,args,kwargs,*,daemon)

由该类实例化得到的对象，表示一个子进程中的任务（尚未启动）

### 参数

group:参数未使用，值始终为None

target:表示调用对象，即子进程要执行的任务

args:表示调用对象的位置参数元组，args=(1,2,'egon',)

kwargs:表示调用对象的字典,kwargs={'name':'egon','age':18}

name:为子进程的名称

强调：

\1. 需要使用关键字的方式来指定参数

\2. args指定的为传给target函数的位置参数，是一个元组形式，必须有逗号

### 方法

p = multiprocessing.Process(target=worker)

p.start()：启动进程，并调用该子进程中的p.run()

p.run():进程启动时运行的方法，正是它去调用target指定的函数，我们自定义类的类中一定要实现该方法

p.terminate():强制终止进程p，不会进行任何清理操作，如果p创建了子进程，该子进程就成了僵尸进程，使用该方法需要特别小心这种情况。如果p还保存了一个锁那么也将不会被释放，进而导致死锁

p.is_alive():如果p仍然运行，返回True

p.join([timeout]):主线程等待p终止（强调：是主线程处于等的状态，而p是处于运行的状态）,timeout是可选的超时时间;需要强调的是，p.join只能join住start开启的进程，而不能join住run开启的进程,例如:p.join()表示主线程等待子进程运行完了,在往下走..

### 属性

p.daemon：默认值为False，如果设为True，代表p为后台运行的守护进程，当p的父进程终止时，p也随之终止，并且设定为True后，p不能创建自己的新进程，必须在p.start()之前设置.

p.name:进程的名称

p.pid：进程的pid

p.exitcode:进程在运行时为None、如果为–N，表示被信号N结束(了解即可)

p.authkey:进程的身份验证键,默认是由os.urandom()随机生成的32字符的字符串。这个键的用途是为涉及网络连接的底层进程间通信提供安全性，这类连接只有在具有相同的身份验证键时才能成功（了解即可）.

### 示例

**注意**:在win中,Process()必须放到 if __name__ == '__main__': 下,由于Windows没有fork，多处理模块启动一个新的Python进程并导入调用模块。如果在导入时调用Process（），那么这将启动无限继承的新进程（或直到机器耗尽资源）。这是隐藏对Process（）内部调用的原，使用if __name__ == “__main __”，这个if语句中的语句将不会在导入时被调用。

创建并开启子进程的2种方式:

1 直接指定target和args参数开启

 

```
# 开进程的方法1:
import time
import random
from multiprocessing import Process

def piao(name):
    """
    开进程要干的事
    :param name: 
    :return: 
    """
    print('%s piaoing..' % name)
    time.sleep(random.randint(1,3))
    print('%s piao end..' % name)

# win下开进程,必须放在main下
if __name__ == '__main__':
    """
    target:子进程要干的事或任务
    args:传参数,元组形式,注意最后写逗号
    start():创建子进程
    """
    p1=Process(target=piao, args=('egon',))
    p2=Process(target=piao, args=('alex',))
    p3=Process(target=piao, args=('jack',))
    p4=Process(target=piao, args=('tom',))

    p1.start() #开启第一个子进程
    print('p1 name is %s.' % p1.name)
    p2.start() #开启第二个子进程
    p3.start() #开启第三个子进程
    p4.start() #开启第四个子进程

    p1.join() # 等待子进程运行完后,继续下面的print
    print('主进程...')
```

2 继承Process类,自定义开启

 

```
# 开进程的方法2:
import time
import random
from multiprocessing import Process

class Piao(Process):
    def __init__(self, name):
        super().__init__()
        self.name = name

    def run(self):
        print('%s piaoing..' % self.name)
        time.sleep(random.randint(1, 3))
        print('%s piao end..' % self.name)

# win下开进程,必须放在main下
if __name__ == '__main__':
    p1=Piao('egon')
    p1.start() # p1.run
    print('父进程...')
```

守护进程:主进程运行完后,子进程跟着一起结束

 

```
import time
import random
from multiprocessing import Process

def fun(name):
    print('%s come back..' % name)
    time.sleep(random.randint(1,3))
    print('%s is gone..' % name)

if __name__ == '__main__':
    """
    p1.daemon=True
    默认值为False
    如果设为True，代表p为后台运行的守护进程
    当p的父进程终止时，p也随之终止
    并且设定为True后，p不能创建自己的新进程
    必须在p.start()之前设置
    """
    p1=Process(target=fun,args=('egon',))
    p1.daemon=True
    p1.start()

    print('主进程.')
    
    运行结果:
    主进程.
```

应用实例:并发连接

 

```
################  服务端  #############################
# 问题:来多少请求,开多少进程,无限制开进程会导致卡死
from multiprocessing import Process
from socket import *
server = socket(AF_INET, SOCK_STREAM)
server.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)
server.bind(('127.0.0.1', 8080))
server.listen(5)

def talk(conn, addr):
    while True:
        try:
            msg = conn.recv(1024)
            if not msg:break
            conn.send(msg.upper())
        except Exception:
            break

if __name__ == '__main__':
    while True:
        conn, addr = server.accept()
        p = Process(target=talk, args=(conn, addr),)
        p.start()

################  客户端1  #############################
from socket import *
client = socket(AF_INET, SOCK_STREAM)
client.connect(('127.0.0.1', 8080))

while True:
    msg = input('>> ').strip()
    if not msg:continue
    client.send(msg.encode('utf-8'))
    msg = client.recv(1024)
    print(msg.decode('utf-8'))

################  客户端2  #############################
from socket import *
client = socket(AF_INET, SOCK_STREAM)
client.connect(('127.0.0.1', 8080))

while True:
    msg = input('>> ').strip()
    if not msg:continue
    client.send(msg.encode('utf-8'))
    msg = client.recv(1024)
    print(msg.decode('utf-8'))
```

## **进程间通信(IPC)**

进程彼此之间互相隔离，要实现进程间通信（IPC），multiprocessing模块支持两种形式：队列和管道，这两种方式都是使用消息传递的

### **Queue**

multiprocessing.Queue(maxsize):创建共享的进程队列,Queue是多进程安全的队列,可以使用Queue实现多进程之间的数据传递.

-maxsize:是队列中允许最大项数,省略则表示5️⃣限制.

队列:先进先出

堆栈:先进后出

### 方法

q = multiprocessing.Queue(maxsize)

**q.put()**方法用以插入数据到队列中.

put方法还有两个可选参数：blocked和timeout.

如果blocked为True(默认值)并且timeout为正值，该方法会阻塞timeout指定的时间，直到该队列有剩余的空间;如果超时，会抛出Queue.Full异常;

如果blocked为False，但该Queue已满，会立即抛出Queue.Full异常.

**q.get()**方法可以从队列读取并且删除一个元素.

同样，get方法有两个可选参数：blocked和timeout.

如果blocked为True(默认值),并且timeout为正值，那么在等待时间内没有取到任何元素，会抛出Queue.Empty异常。如果blocked为False，有两种情况存在，如果Queue有一个值可用，则立即返回该值，否则，如果队列为空，则立即抛出Queue.Empty异常.

q.get_nowait():同q.get(False)

q.put_nowait():同q.put(False)

q.empty():调用此方法时q为空则返回True，该结果不可靠，比如在返回True的过程中，如果队列中又加入了项目。

q.full()：调用此方法时q已满则返回True，该结果不可靠，比如在返回True的过程中，如果队列中的项目被取走。

q.qsize():返回队列中目前项目的正确数量，结果也不可靠，理由同q.empty()和q.full()一样

q.cancel_join_thread():不会在进程退出时自动连接后台线程。可以防止join_thread()方法阻塞

q.close():关闭队列，防止队列中加入更多数据。调用此方法，后台线程将继续写入那些已经入队列但尚未写入的数据，但将在此方法完成时马上关闭。如果q被垃圾收集，将调用此方法。关闭队列不会在队列使用者中产生任何类型的数据结束信号或异常。例如，如果某个使用者正在被阻塞在get()操作上，关闭生产者中的队列不会导致get()方法返回错误。

q.join_thread()：连接队列的后台线程。此方法用于在调用q.close()方法之后，等待所有队列项被消耗。默认情况下，此方法由不是q的原始创建者的所有进程调用。调用q.cancel_join_thread方法可以禁止这种行为

### **生产者消费者模型**

生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题.

生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。

在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序的整体处理数据的速度.

在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。

### 实例

基于队列实现生产者消费者模型

 

```
#!/usr/bin/env python
# -*- coding:utf-8 -*-
__Author__ = 'xiaofei'

from multiprocessing import Process, Queue
import time, random, os

def consumer(q, name):
    """
    消费者任务
    :param q: 
    :param name: 
    :return: 
    """
    while True: # 不断的去队列读取
        time.sleep(random.randint(1,3))  # 模拟读取的间隔
        res = q.get()  # 获取的结果实例化
        if res is None:break  # 如果获取的结果是None,则停止获取
        print('\033[41m消费者 %s 拿到了 %s .\033[0m' % (name, res))

def  producer(seq, q, name):
    """
    生产者任务
    :return: 
    """
    for item in seq:  # 遍历一个可循环对象
        time.sleep(random.randint(1,3))  # 模拟生产时间间隔
        q.put(item)  # 将生产的包子放到队列中
        print('\033[42m生产者 %s 生产了 %s .\033[0m' % (name, item))
    q.put(None)  # 放一个None,代表生产完了.

if __name__ == '__main__':

    q = Queue()  # 定义队列长度
    
    c = Process(target=consumer, args=(q, 'egon'),)  # 传参给子进程c
    c.start()  # 开启一个消费者子进程c

    seq = ['包子%s' % i for i in range(10)]  # 列表生成式,生产10个包子
    p = Process(target=producer, args=(seq, q, '厨师'))  # 传参给子进程p,往队列放包子
    p.start() # 开启生产者子进程p
    c.join()  # 等待子进程c结束

    print('主进程..')
```

那么如果生产者想要知道消费者的确获取到了包子,如何做呢?

需要导入另外一个模块: JoinableQueue()

那么修改如下:

 

```
#!/usr/bin/env python
# -*- coding:utf-8 -*-
__Author__ = 'xiaofei'

from multiprocessing import Process, JoinableQueue
import time, random, os

def consumer(q, name):
    """
    消费者任务
    :param q: 
    :param name: 
    :return: 
    """
    while True: # 不断的去队列读取
        time.sleep(random.randint(1,3))  # 模拟读取的间隔
        res = q.get()  # 获取的结果实例化
        q.task_done() # 获取到一个包子,就发一次信号
        if res is None:break  # 如果获取的结果是None,则停止获取
        print('\033[41m消费者 %s 拿到了 %s .\033[0m' % (name, res))

def  producer(seq, q, name):
    """
    生产者任务
    :return: 
    """
    for item in seq:  # 遍历一个可循环对象
        time.sleep(random.randint(1,3))  # 模拟生产时间间隔
        q.put(item)  # 将生产的包子放到队列中
        print('\033[42m生产者 %s 生产了 %s .\033[0m' % (name, item))
    q.join() # 等待消费者的task_done信号
    print('包子卖完了..')

if __name__ == '__main__':

    q = JoinableQueue()  # 定义队列长度
    
    # 开启多个消费者子进程c*
    c1 = Process(target=consumer, args=(q, '消费者1'),)  # 传参给子进程c1
    c2 = Process(target=consumer, args=(q, '消费者2'),)  # 传参给子进程c2
    c3 = Process(target=consumer, args=(q, '消费者3'),)  # 传参给子进程c3
    
    c1.daemon=True  # 设置c1为后台运行的守护进程，当c1的父进程终止时，c1也随之终止
    c2.daemon=True  # 设置c2为后台运行的守护进程，当c2的父进程终止时，c2也随之终止
    c3.daemon=True  # 设置c3为后台运行的守护进程，当c3的父进程终止时，c3也随之终止
    
    c1.start()  # 开启一个消费者子进程c1
    c2.start()  # 开启一个消费者子进程c2
    c3.start()  # 开启一个消费者子进程c3

    # 开启1个生产者子进程p,也可开启多个生产者
    seq = ['包子%s' % i for i in range(10)]  # 列表生成式,生产10个包子
    p = Process(tar get=producer, args=(seq, q, '厨师'))  # 传参给子进程p,往队列放包子
    p.start() # 开启生产者子进程p
    p.join()  # 主进程等待子进程p结束,p等待c把数据都取完,c取完数据后,p.join不再阻塞,进而主进程运行下面的print,主进程结束后回收守护进程c.

    print('主进程..')
```



