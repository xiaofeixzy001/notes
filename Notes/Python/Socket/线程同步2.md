[TOC]

# Barrier

栅栏，屏障，可以想象成路障、道闸。

Python3.2引入的新功能。

## 方法

bar = Barrier(parties, action=None, timeout=None)

构建Barrier对象，指定参与方数目。timeout是wait方法未指定超时的默认值。

bar.n_waiting

当前在屏障中等待的线程数。

bar.parties

各方数，就是需要多少个等待。

bar.wait(timeout=None)

等待通过屏障。返回0到线程数-1的整数，每个线程返回不同。如果wait方法设置了超时，并超时发送，屏障将处于broken状态。

bar.broken

打破屏障，如果屏障处于打破的状态，返回True，可以理解为房间尚未创建，玩家无法加入状态。

bar.abort()

将屏障设置为broken状态，等待中的线程或调用等待方法的线程中都会抛出BrokenBarrierError异常，直到reset方法来恢复屏障。

bar.reset()

恢复屏障，重新开始拦截。

## 示例

 

```
from threading import Event, Thread, Barrier
import threading
import logging
import time

FORMAT = "%(asctime)s %(threadName)s %(thread)d %(message)s"
logging.basicConfig(format=FORMAT, level=logging.INFO)

def worker(barrier: Barrier):
    logging.info("waiting for {} threads.".format(barrier.n_waiting))
    try:
        barrier_id = barrier.wait()
        logging.info('after barrier {}'.format(barrier_id))
    except threading.BrokenBarrierError:
        logging.info("Broken Barrier.")

barrier = Barrier(3)
for x in range(6):
    time.sleep(1)
    Thread(target=worker, name='worker-{}'.format(x), args=(barrier,)).start()

logging.info('started')
```

可以理解为游戏房间，预设3个玩家位置，满人后开始一波游戏，下一波玩家等待。

## broken示例

将上述示例的线程启动方式修改如下：

 

```
def worker(barrier: Barrier):
    logging.info("waiting for {} threads.".format(barrier.n_waiting))
    try:
        barrier_id = barrier.wait()
        logging.info('after barrier {}'.format(barrier_id))
    except threading.BrokenBarrierError:
        logging.info("Broken Barrier.")

barrier = Barrier(3)

for x in range(0, 9):
    if x == 2:
        barrier.abort()  # 如果玩家数为2,房间解散
    elif x == 6:
        barrier.reset()  # 如果玩家数为6,房间被创建
    Event().wait(2)
    Thread(target=worker, name='worker-{}'.format(x), args=(barrier,)).start()

logging.info('started')
```

上面示例中，屏障中等待了2个线程，屏障就被broken了，此时已经处于屏障中的线程和后来的线程，进来后发现屏障处于broken状态，都会抛BrokenBarrierError异常，直到屏障被reset恢复，才继续按照指定位置数进行拦截。

线程0和1进入屏障等待，线程2一进来，屏障被broken，0和1被迫赶出屏障，各自抛一个异常。然后线程3,4,5执行到此，发现broken状态，同样抛异常，当线程6进来时，屏障被reset，6,7,8进入屏障等待

## wait示例

如果wait方法超时发生，屏障将处于broken状态，直到reset

 

```
def worker(barrier: Barrier, i: int):
    logging.info("waiting for {} threads.".format(barrier.n_waiting))
    try:
        logging.info(barrier.broken)  # 是否broken
        if i < 3:
            barrier_id = barrier.wait(1)  # 超时后,屏障broken,1秒内如果屏障内没有满员就broken
        else:
            if i == 6:
                barrier.reset()  # 恢复屏障
            barrier_id = barrier.wait()
        logging.info('Running {}'.format(barrier_id))
    except threading.BrokenBarrierError:
        logging.info("***Broken***")


barrier = Barrier(3)
for x in range(0, 9):
    Event().wait(2)
    Thread(target=worker, name='worker-{}'.format(x), args=(barrier, x)).start()

logging.info('started')
```

## Barrier应用

1 并发初始化

所有线程都必须初始化完成后，才能继续工作，例如运行前加载数据、检查，如果这些工作没完成，就开运行，将不能正常工作。

10个线程10种工作准备，每个线程负责一种工作，只有这10个线程都完成后，才能继续工作，先完成的要等待后完成的线程。

例如，启动一个程序，需要先加载磁盘文件、缓存预热、初始化连接池等工作，这些工作可以齐头并进，不过只有都满足了，程序才能继续向后执行。如果有一项失败，就要abort，barrier置为broken，所有线程收到异常退出。

2 工作量

有10个计算任务，完成6个，就算工作完成。

# semaphore

和Lock很像，信号量对象内部维护一个倒计数器，每一次acquire都会减1，为0时阻塞线程请求，直到其他线程对信号量release后，计数器大于0，恢复阻塞的线程。

个人理解：放3把锁，谁用谁来拿，计数器为0表示无锁可拿，只有等归还锁后才可以继续拿。

## 使用方法

sema = Semaphore(value=1)：构造方法。value小于0,抛ValueError异常

sema.acquire(blocking=True, timeout=None): 获取信号量，计数器减1(初始为value)，获取成功返回True

sema.release(): 释放信号量，计数器加1

计数器永远不会低于0

 

```
from threading import Semaphore
import threading
import logging

# 输出格式定义
FORMAT = "%(asctime)-15s\t [%(threadName)s, %(thread)8d] %(message)s"
logging.basicConfig(format=FORMAT, level=logging.INFO)


def worker(s: Semaphore):
    logging.info("In sub thread.")
    logging.info(s.acquire())  # 线程执行到此阻塞
    logging.info("Sub sthread over.")


s = Semaphore(3)  # 放3个锁
logging.info(s.acquire())  # 取一把
print(s._value)
logging.info(s.acquire())  # 取一把
print(s._value)
logging.info(s.acquire())  # 取一把
print(s._value)
# logging.info(s.acquire())  # 再取没有了,阻塞

# 起线程
threading.Thread(target=worker, args=(s,)).start()
time.sleep(2)

logging.info(s.acquire(False))  # 获取锁,有就True,没有Fasle,不阻塞
logging.info(s.acquire(timeout=3))  # 阻塞3秒

# 归还锁
logging.info("released")
s.release()
```

实例：同时只有5个线程可以获得semaphore,即可以限制最大连接数为5

 

```
import threading
import time

semaphore = threading.Semaphore(5)

def func():
    if semaphore.acquire():
        print(threading.currentThread().getName() + 'get semaphore')
        time.sleep(2)
        semaphore.release()

for i in range(20):
    t1 = threading.Thread(target=func)
    t1.start()

'''
每2秒执行一次，每次5个线程
'''
```

与进程池是完全不同的概念，进程池Pool(4)，最大只能产生4个进程，而且从头到尾都只是这四个进程，不会产生新的，而信号量是产生一堆线程/进程。

## BoundedSemaphore

有界信号量，不允许使用release超出初始值的范围，否则抛出ValueError异常。

## 应用

连接池

因为资源有限，且开启一个连接成本高，所以，使用连接池。

## 信号量和锁

锁 ，只允许同一个时间一个线程独占资源。它是特殊的信号量，即信号量计数器初始值为 1.

信号量，可以多个线程访问共享资源，但这个共享资源数量有限。

# GIL

Global Interpreter Lock 全局解释器锁

CPython在解释器进程级别有一把锁，叫做GIL全局解释器锁。保证进程中，只有一个线程执行字节码，甚至在多核CPU的情况下，也是如此。

Python代码的执行由Python 虚拟机(也叫解释器主循环，CPython版本)来控制，Python 在设计之初就考虑到要在解释器的主循环中，同时只有一个线程在执行，即在任意时刻，只有一个线程在解释器中运行。对Python 虚拟机的访问由全局解释器锁（GIL）来控制，正是这个锁能保证同一时刻只有一个线程在运行。

## 执行方式

在多线程环境中，Python 虚拟机按以下方式执行：

\1. 设置GIL

\2. 切换到一个线程去运行

\3. 运行代码：

\- 指定数量的字节码指令

\- 线程主动让出控制（可以调用time.sleep(0)）

\- 把线程设置为睡眠状态

\- 解锁GIL

\- 再次重复以上所有步骤

在调用外部代码（如C/C++扩展函数）的时候，GIL 将会被锁定，直到这个函数结束为止（由于在这期间没有Python 的字节码被运行，所以不会做线程切换）。

## IO和CPU密集型

IO密集型: 由于线程阻塞，就会调度其他线程；

CPU密集型: 当前线程可能会连续的获得GIL，导致其他线程几乎无法使用CPU。

在CPython中由于有GIL存在，IO密集型，使用多线程，CPU密集型，使用多进程，绕开GIL。

在CPython解释器中，同一个进程下开启的多线程，同一时刻只能有一个线程执行，无法利用多核优势；

对计算来说，cpu越多越好，但是对于I/O来说，再多的cpu也没用；

当然对于一个程序来说，不会是纯计算或者纯I/O，我们只能相对的去看一个程序到底是计算密集型还是I/O密集型，从而进一步分析python的多线程有无用武之地；

Python中绝大多数内置数据结构的读写都是原子操作，由于GIL的存在，Python的内置数据类型在多线程编程的时候就变成了安全的了，但是实际上它们本身不是线程安全类型的。

## 示例

我们有四个任务需要处理，处理方式肯定是要玩出并发的效果，解决方案可以是：

方案一：开启四个进程

方案二：一个进程下，开启四个线程

\- 单核情况下，分析结果:

如果四个任务是计算密集型，没有多核来并行计算，方案一徒增了创建进程的开销，方案二胜

如果四个任务是I/O密集型，方案一创建进程的开销大，且进程的切换速度远不如线程，方案二胜

\- 多核情况下，分析结果：

如果四个任务是计算密集型，多核意味着并行计算，在python中一个进程中同一时刻只有一个线程执行用不上多核，方案一胜

如果四个任务是I/O密集型，再多的核也解决不了I/O问题，方案二胜

\- 结论：现在的计算机基本上都是多核，python对于计算密集型的任务开多线程的效率并不能带来多大性能上的提升，甚至不如串行(没有大量切换)，但是，对于IO密集型的任务效率还是有显著提升的。

## 应用

多线程用于IO密集型，如socket，爬虫，web；

多进程用于计算密集型，如金融分析；

## GIL VS Lock

机智的同学可能会问到这个问题，就是既然你之前说过了，Python已经有一个GIL来保证同一时间只能有一个线程来执行了，为什么这里还需要lock?

首先我们需要达成共识：锁的目的是为了保护共享的数据，同一时间只能有一个线程来修改共享的数据。

然后，我们可以得出结论：保护不同的数据就应该加不同的锁。

最后，问题就很明朗了，GIL 与Lock是两把锁，保护的数据不一样，前者是解释器级别的（当然保护的就是解释器级别的数据，比如垃圾回收的数据），后者是保护用户自己开发的应用程序的数据，很明显GIL不负责这件事，只能用户自定义加锁处理，即Lock。

详细的：

因为Python解释器帮你自动定期进行内存回收，你可以理解为python解释器里有一个独立的线程，每过一段时间它起wake up做一次全局轮询看看哪些内存数据是可以被清空的，此时你自己的程序 里的线程和 py解释器自己的线程是并发运行的，假设你的线程删除了一个变量，py解释器的垃圾回收线程在清空这个变量的过程中的clearing时刻，可能一个其它线程正好又重新给这个还没来及得清空的内存空间赋值了，结果就有可能新赋值的数据被删除了，为了解决类似的问题，python解释器简单粗暴的加了锁，即当一个线程运行时，其它人都不能动，这样就解决了上述的问题， 这可以说是Python早期版本的遗留问题。

 

```
import datetime
import threading

start = datetime.datetime.now()

def calc():
    sum = 0
    for _ in range(100000000):
        sum += 1

ts = []
t = threading.Thread(target=calc)
ts.append(t)
t.start()

t = threading.Thread(target=calc)
ts.append(t)
t.start()

t = threading.Thread(target=calc)
ts.append(t)
t.start()

t = threading.Thread(target=calc)
ts.append(t)
t.start()

t = threading.Thread(target=calc)
ts.append(t)
t.start()

for t in ts:
    t.join()
# 25.187066

calc()
calc()
calc()
calc()
calc()
# 25.279274

delta = (datetime.datetime.now() - start).total_seconds()
print(delta)
```



